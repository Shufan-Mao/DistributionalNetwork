import math
from typing import List
import networkx as nx
from collections import defaultdict

from src.networks.network import NetworkBaseClass
from src.params import LONParams

VERBOSE = True


class LON(NetworkBaseClass):
    """
    co-occurrence graph, generated by joining sub-graphs, made of consecutively ordered words, at shared words
    """

    def __init__(self,
                 params: LONParams,
                 seq_tok: List[List[str]],
                 decay: float
                 ):
        NetworkBaseClass.__init__(self, decay)

        self.params = params
        self.seq_tok = seq_tok

        self.freq_dict = defaultdict(int)

        self.sr_bank = {}  # for caching sr scores

    def train(self):

        network_edges = []
        network_nodes = []
        for tokens in self.seq_tok:
            edges = []
            for i in range(len(tokens) - 1):
                edges.append((tokens[i],tokens[i+1]))
            for token in tokens:
                if token not in self.freq_dict:
                    self.freq_dict[token] = 1
                else:
                    self.freq_dict[token] = self.freq_dict[token] + 1
            network_edges.extend(edges)
            network_nodes.extend(tokens)

        self.node_list = list(set(network_nodes))

        network_edge_dict = {}
        for edge in network_edges:
            if edge in network_edge_dict:
                network_edge_dict[edge] = network_edge_dict[edge] + 1
            else:
                network_edge_dict[edge] = 1

        weighted_network_edge = []
        for edge in network_edge_dict:
            weighted_network_edge.append(edge + (math.log10(network_edge_dict[edge] + 1),))

        if VERBOSE:
            print()
            print('Weighted Edges:')
            for edge in weighted_network_edge:
                print(self.node_list.index(edge[0]), self.node_list.index(edge[1]), edge)
            print()

        # make network
        self.network = nx.Graph()
        self.network.add_weighted_edges_from(weighted_network_edge)

    def calc_sr_scores(self, verb, theme, instruments, step_bound=None):
        """compute sr scores for a single row in the blank sr data frame."""

        if step_bound:  # consider recurrent activation with spreading decay
            if verb not in self.sr_bank:
                self.sr_bank[verb] = self.recurrent_spreading_relatedness(verb, self.node_list, step_bound)
            if theme not in self.sr_bank:
                self.sr_bank[theme] = self.recurrent_spreading_relatedness(verb, self.node_list, step_bound)

        else:  # non-recurrent activation of limited steps
            if verb not in self.sr_bank:
                self.sr_bank[verb] = self.non_recurrent_relatedness(verb, instruments, [])
            if theme not in self.sr_bank:
                self.sr_bank[theme] = self.non_recurrent_relatedness(theme, instruments, [])

        scores = []
        for instrument in instruments:  # instrument columns start after the 3rd column
            sr = math.log(self.sr_bank[verb][instrument] * self.sr_bank[theme][instrument])
            scores.append(sr)

        return scores

    def get_performance(self):
        return {}